{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f0131e",
   "metadata": {},
   "source": [
    "### Creating a LLMChain from scratch (as done by langchain initially)\n",
    "Creating two classes- 1. for llm 2. for prompt. That will be used by users to interact with any llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809f7f0",
   "metadata": {},
   "source": [
    "#### Creting llm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "329e84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e22857d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoLLM:\n",
    "    def __init__(self):\n",
    "        print(\"LLM created\")\n",
    "    \n",
    "    def predict(self, prompt):\n",
    "        response_list=[\"Delhi is the capital of India\", \"AI is Artifiical Intelligence\", \"I am in Bangalore\"]\n",
    "\n",
    "        return {'response': random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91772256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'AI is Artifiical Intelligence'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating object of class\n",
    "llm=demoLLM()\n",
    "\n",
    "llm.predict(\"where are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed2f66",
   "metadata": {},
   "source": [
    "#### Creating a class for Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b640ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoPromptTemplate:\n",
    "    def __init__(self, template, input_variables):\n",
    "        self.template=template\n",
    "        self.input_variables=input_variables\n",
    "    \n",
    "    def format(self, input_dict):\n",
    "        return self.template.format(**input_dict) #format function used in this line builtin for dictionary that fills the placeholders '{}' with the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67cd4b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a short poem about India'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template=demoPromptTemplate(\n",
    "    template=\"Write a {length} poem about {topic}\",\n",
    "    input_variables=['length','topic']\n",
    ")\n",
    "\n",
    "template.format({'topic':'India', 'length':'short'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde5638",
   "metadata": {},
   "source": [
    "Note that these classes behave how the actual llm and prompt classes will.\n",
    "\n",
    "Now to create an application  using these two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c53ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=template.format({'topic':'India', 'length':'short'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e89677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'AI is Artifiical Intelligence'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=demoLLM()\n",
    "llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25142b",
   "metadata": {},
   "source": [
    "Now creating an LLMChain to make it easier for the users to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c56bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoLLMChain:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.llm=llm\n",
    "        self.prompt=prompt\n",
    "    \n",
    "    def run(self, input_dict):\n",
    "        prompt=self.prompt.format(input_dict)\n",
    "        result=self.llm.predict(prompt)\n",
    "\n",
    "        return result['response']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d94f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am in Bangalore'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template=demoPromptTemplate(\n",
    "    template=\"Write a {length} poem about {topic}\",\n",
    "    input_variables=['length','topic']\n",
    ")\n",
    "llm=demoLLM()\n",
    "\n",
    "chain=demoLLMChain(llm, template)\n",
    "chain.run({'topic':'India', 'length':'short'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8a9ee",
   "metadata": {},
   "source": [
    "As can be seen, we don't have to format the prompt and .predict on llm to get the response. But creating so many such chains caused problems. And this was created as llm and prompts can't be connected by themselves as not starndardized- llm used predict() and prompt uses format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5ae9d",
   "metadata": {},
   "source": [
    "## Making Standardized components (Runnables)\n",
    "Task is to ensure all the runnables have a common method (invoke). The best way to do it is by inheriting a common class that has this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "#ABC is an abstract class which means it's object can't be created directly. It can only be inherited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c2aa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable(ABC):\n",
    "    \n",
    "    @abstractmethod #abstract methods act as a placeholder that should mandatorily be implemented in the clas that inherits it\n",
    "    def invoke(input_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c6a3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoLLM(Runnable):\n",
    "    def __init__(self):\n",
    "        print(\"LLM created\")\n",
    "    \n",
    "    def invoke(self, prompt):\n",
    "        response_list=[\"Delhi is the capital of India\", \"AI is Artifiical Intelligence\", \"I am in Bangalore\"]\n",
    "        return {'response': random.choice(response_list)}\n",
    "\n",
    "    #Should we remove predict? NO! People who are already using it will get their code crashed. Instead print a warning message saying this method will be depricated, start using...\n",
    "    def predict(self, prompt):\n",
    "        response_list=[\"Delhi is the capital of India\", \"AI is Artifiical Intelligence\", \"I am in Bangalore\"]\n",
    "\n",
    "        return {'response': random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6bd2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoPromptTemplate(Runnable):\n",
    "    def __init__(self, template, input_variables):\n",
    "        self.template=template\n",
    "        self.input_variables=input_variables\n",
    "\n",
    "    def invoke(self, input_dict):\n",
    "        return self.template.format(**input_dict)    \n",
    "    \n",
    "    def format(self, input_dict):\n",
    "        return self.template.format(**input_dict) #format function used in this line builtin for dictionary that fills the placeholders '{}' with the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0da2e",
   "metadata": {},
   "source": [
    "Now both the objects- llm and prompt have same method to communicate i.e. invoke. This is helpful as these can be connected to create long chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "345b6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class that connects two runnables\n",
    "\n",
    "class RunnableConnector(Runnable):\n",
    "    def __init__(self, *args): # can take any number of components like prompts, models etc.\n",
    "        self.components=args\n",
    "\n",
    "    def invoke(self, input_data):\n",
    "        for component in self.components: #take components one by one and give them previous' component input \n",
    "            input_data=component.invoke(input_data)\n",
    "            \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb7781fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'Delhi is the capital of India'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=demoLLM()\n",
    "template=demoPromptTemplate(\n",
    "    template=\"Write a {length} poem about {topic}\",\n",
    "    input_variables=['length','topic']\n",
    ")\n",
    "\n",
    "chain=RunnableConnector(template,llm)\n",
    "chain.invoke({'topic':'India', 'length':'short'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014049db",
   "metadata": {},
   "source": [
    "As can be seen, now having a single runnableconnector class is enough compared to having a NEW CHAIN FOR CONNECTING DIFFERENT TYPES OF COMPONENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e551e9",
   "metadata": {},
   "source": [
    "Creating another object (bigger chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ee8dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demoStrOutputParser(Runnable):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def invoke(self, input_text):\n",
    "        return input_text['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "749cceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI is Artifiical Intelligence'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=demoLLM()\n",
    "template=demoPromptTemplate(\n",
    "    template=\"Write a {length} poem about {topic}\",\n",
    "    input_variables=['length','topic']\n",
    ")\n",
    "parser=demoStrOutputParser()\n",
    "chain=RunnableConnector(template,llm, parser)\n",
    "chain.invoke({'topic':'India', 'length':'short'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ab43a",
   "metadata": {},
   "source": [
    "#### Combining two chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7625b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI is Artifiical Intelligence'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1=demoPromptTemplate(\n",
    "    template=\"Write a joke about {topic}\",\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt2=demoPromptTemplate(\n",
    "    template=\"explain the follwing joke: {response}\",\n",
    "    input_variables=['response']\n",
    ")\n",
    "llm=demoLLM()\n",
    "\n",
    "chain1= RunnableConnector(prompt1, llm)\n",
    "chain2=RunnableConnector(prompt2,llm, parser)\n",
    "\n",
    "merge_chain=RunnableConnector(chain1, chain2)\n",
    "\n",
    "merge_chain.invoke({'topic':'America'})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
